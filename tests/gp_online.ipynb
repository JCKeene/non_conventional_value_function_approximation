{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('rl_vfa_venv': venv)"
  },
  "interpreter": {
   "hash": "ca6e9933f728d920a33c4385152fc811e414d8d97bad348677111d3aff399912"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(env, epsilon, obs, X, alpha, explore):\n",
    "    if (explore and np.random.random_sample() < epsilon):\n",
    "        action = env.action_space.sample()\n",
    "    else:        \n",
    "        Q = [_predict(np.concatenate([obs, actions[i]],-1).reshape(1,-1), X, alpha) for i in range(env.action_space.n)]\n",
    "        action = np.argmax(Q)\n",
    "    return action    \n",
    "\n",
    "def _predict(x, X, alpha):\n",
    "    return alpha.T @ kernel(X,x)\n",
    "\n",
    "def _inc_dim_v(v):\n",
    "    return np.pad(v, ((0,1),(0,0)))\n",
    "\n",
    "def _inc_dim_m(m):\n",
    "    return np.pad(m, ((0,1),(0,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-d1a7349929e4>, line 27)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-d1a7349929e4>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    episode_returns = 0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "epsilon = 0.9\n",
    "actions =  [[1,0],[0,1]]\n",
    "learning_rate = 0.01\n",
    "gamma = 0.99\n",
    "\n",
    "kernel = rbf_kernel\n",
    "obs = env.reset()\n",
    "action = env.action_space.sample()\n",
    "\n",
    "sigma_0 = 1\n",
    "x = np.concatenate([obs, actions[action]],-1).reshape(1,-1)\n",
    "X = x\n",
    "alpha = np.array([[1]])\n",
    "C = np.array([[1]])\n",
    "mew = 1\n",
    "sigma = 1\n",
    "r = 1\n",
    "e = np.array([[1]])\n",
    "\n",
    "n_eps = 10\n",
    "\n",
    "for i in range(n_eps):\n",
    "\n",
    "    obs = env.reset()\n",
    "\n",
    "    episode_returns = 0\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        next_obs, reward, done, _ = env.step(action)\n",
    "        print(reward)\n",
    "        \n",
    "        Q_values = [_predict(np.concatenate([next_obs, actions[i]],-1).reshape(1,-1), X, alpha) for i in range(env.action_space.n)]\n",
    "        # print(f\"Q_values: {Q_values}\")\n",
    "        Q_max = np.max(Q_values)\n",
    "        # print(f\"Q_max: {Q_max}\")\n",
    "        Q_prev = _predict(x, X, alpha).item()\n",
    "        # print(f\"Q_prev: {Q_prev}\")\n",
    "        \n",
    "        x = np.concatenate([next_obs, actions[action]],-1).reshape(1,-1)\n",
    "        # print(f\"x: {x}\")\n",
    "        k = kernel(x, x)\n",
    "        # print(f\"k: {k}\")\n",
    "        kk = kernel(X, x)\n",
    "        # print(f\"kk: {kk}\")\n",
    "        # K = kernel(X)\n",
    "        # print(f\"K: {K}\")\n",
    "        \n",
    "        mew = alpha.T @ kk\n",
    "        # print(f\"mew: {mew}\")\n",
    "        sigma = k + kk.T @ C @ kk\n",
    "        # print(f\"sigma: {sigma}\")\n",
    "        \n",
    "        r = -1/(sigma_0**2 + sigma)\n",
    "        # print(f\"r: {r}\")\n",
    "        y = (reward + gamma * (1-done) * Q_max - Q_prev) / (sigma_0**2 + sigma)\n",
    "        # print(f\"y: {y}\")\n",
    "        e = np.vstack([[0], e])\n",
    "        # print(f\"e: {e}\")\n",
    "        s = _inc_dim_v(C@kk) + e\n",
    "        # print(f\"s: {s}\")\n",
    "        C = _inc_dim_m(C) + r*(s@s.T)\n",
    "        # print(f\"C: {C}\")\n",
    "        alpha = _inc_dim_v(alpha) + y*s  \n",
    "        # print(f\"alpha: {alpha}\")\n",
    "        \n",
    "        X = np.vstack([X, x])\n",
    "        # print(f\"X: {X}\")\n",
    "\n",
    "        obs = next_obs\n",
    "        action = act(env, epsilon, obs, X, alpha, explore=True)\n",
    "\n",
    "        episode_returns += 1\n",
    "        \n",
    "    print(f\"Episode: {i}, Return: {episode_returns\")\n",
    "\n",
    "           \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}