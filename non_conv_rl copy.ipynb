{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('rl_vfa_venv': venv)"
  },
  "interpreter": {
   "hash": "ca6e9933f728d920a33c4385152fc811e414d8d97bad348677111d3aff399912"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from function_approximators.replay import ReplayBuffer\n",
    "import torch\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# env = WindyGridworldEnv()\n",
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def act(env, model, s, epsilon, explore):\n",
    "    if explore and np.random.random_sample() < epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:       \n",
    "        try:\n",
    "            Q = [model.predict(np.concatenate([s, actions[i]],-1).reshape(1,-1)) for i in range(env.action_space.n)]\n",
    "            # print(Q)\n",
    "            action = np.argmax(Q)\n",
    "            # print(action)\n",
    "        except:\n",
    "            # print(\"init\")\n",
    "            action = env.action_space.sample()\n",
    "    return action\n",
    "\n",
    "def update(env, model, batch, gamma):\n",
    "    inputs = np.concatenate([batch.states, [actions[int(i.item())] for i in batch.actions]], -1)\n",
    "    preds = []\n",
    "    try:\n",
    "        for i in range(env.action_space.n):\n",
    "            next_inputs = np.concatenate([batch.next_states, np.zeros((batch.actions.size()[0], 1)) + actions[i]], -1)\n",
    "            preds.append(model.predict(next_inputs))\n",
    "        preds = np.array(preds).T\n",
    "        outputs = np.array(batch.rewards + gamma * (1-batch.done) * np.max(preds, 1).reshape(-1,1)).reshape(-1)\n",
    "    except:\n",
    "        # print(\"init\")\n",
    "        outputs = np.array(batch.rewards).reshape(-1)\n",
    "        \n",
    "    model.fit(inputs, outputs)\n",
    "    \n",
    "    # return q_loss\n",
    "\n",
    "\n",
    "def play_episode(env, model, replay_buffer, batch_size, gamma, epsilon, explore, train, episode_length):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    episode_timesteps = 0\n",
    "    episode_return = 0\n",
    "\n",
    "    while not done:\n",
    "        a = act(env, model, s, epsilon, explore=explore)\n",
    "        s_next, r, done, _ = env.step(a)\n",
    "        if train:\n",
    "            replay_buffer.push(\n",
    "                np.array(s, dtype=np.float32),\n",
    "                np.array([a], dtype=np.float32),\n",
    "                np.array(s_next, dtype=np.float32),\n",
    "                np.array([r], dtype=np.float32),\n",
    "                np.array([done], dtype=np.float32),\n",
    "                )\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                batch = replay_buffer.sample(batch_size)\n",
    "                update(env, model, batch, gamma)\n",
    "        episode_timesteps += 1\n",
    "        episode_return += r\n",
    "        \n",
    "        if episode_timesteps == episode_length:\n",
    "            break\n",
    "        s = s_next\n",
    "\n",
    "    return episode_timesteps, episode_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(max_depth=5, min_samples_split=5, min_samples_leaf=5)\n",
    "# model = RandomForestRegressor(n_estimators=5, max_depth=20)\n",
    "# model = MLPRegressor()\n",
    "replay_buffer = ReplayBuffer(1000)\n",
    "# actions = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "actions =  [[1,0],[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  5%|‚ñç         | 992/20000 [00:08<02:33, 123.47it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 1000 is out of bounds for axis 0 with size 1000",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-50f0bf42f7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtimesteps_elapsed\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         episode_timesteps, _ = play_episode(env, model, replay_buffer, batch_size=batch_size, gamma=gamma, epsilon=epsilon, \n\u001b[0m\u001b[1;32m     14\u001b[0m                                             explore=True, train=True, episode_length=episode_length)\n\u001b[1;32m     15\u001b[0m         \u001b[0mtimesteps_elapsed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mepisode_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-910eb545e6a8>\u001b[0m in \u001b[0;36mplay_episode\u001b[0;34m(env, model, replay_buffer, batch_size, gamma, epsilon, explore, train, episode_length)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0ms_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             replay_buffer.push(\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_vfa/function_approximators/replay.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_vfa/function_approximators/replay.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1000 is out of bounds for axis 0 with size 1000"
     ]
    }
   ],
   "source": [
    "max_timesteps = 20000\n",
    "timesteps_elapsed = 0\n",
    "episode_length = 200\n",
    "eval_freq = 1000\n",
    "eval_episodes = 5\n",
    "gamma = 0.99\n",
    "epsilon = 1\n",
    "batch_size = 512\n",
    "\n",
    "with tqdm(total=max_timesteps) as pbar:\n",
    "\n",
    "    while timesteps_elapsed < max_timesteps:\n",
    "        episode_timesteps, _ = play_episode(env, model, replay_buffer, batch_size=batch_size, gamma=gamma, epsilon=epsilon, \n",
    "                                            explore=True, train=True, episode_length=episode_length)\n",
    "        timesteps_elapsed += episode_timesteps\n",
    "        pbar.update(episode_timesteps)\n",
    "\n",
    "        if timesteps_elapsed % eval_freq < episode_timesteps:\n",
    "            eval_returns = 0\n",
    "            for _ in range(eval_episodes):\n",
    "                _ , episode_return = play_episode(env, model, replay_buffer, batch_size=batch_size, gamma=gamma, epsilon=epsilon, \n",
    "                                                explore=False, train=False, episode_length=episode_length)\n",
    "                eval_returns += episode_return / eval_episodes\n",
    "\n",
    "            epsilon = max(epsilon*0.7,0.03)\n",
    "            # tree.plot_tree(model)\n",
    "            pbar.write(f\"Evaluation at timestep {timesteps_elapsed} returned a mean returns of {eval_returns}\")\n",
    "            pbar.write(f\"Epsilon = {epsilon}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.08800144 -0.8159531   0.07608863  1.172605    1.         -0.10432051\n -0.62189823  0.09954073  0.9047134 ]\n[ 0.00810471  0.01968517  0.00894894  0.0262062   0.          0.00849841\n -0.17556398  0.00947307  0.32169914]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import scipy.spatial.distance as dist\n",
    "n = replay_buffer.memory.states.shape[0]\n",
    "\n",
    "a = np.concatenate((replay_buffer.memory[0][0], replay_buffer.memory[1][0], replay_buffer.memory[2][0]))\n",
    "print(a)\n",
    "\n",
    "distances = []\n",
    "for i in range(n):\n",
    "    b = np.concatenate((replay_buffer.memory[0][i], replay_buffer.memory[1][i], replay_buffer.memory[2][i]))\n",
    "    distances.append(dist.euclidean(a,b))\n",
    "\n",
    "[(i,d) for (i,d) in enumerate(distances) if d < 0.1]\n",
    "\n",
    "print(np.concatenate((replay_buffer.memory[0][2], replay_buffer.memory[1][2], replay_buffer.memory[2][2])))\n",
    "\n",
    "distances\n",
    "\n",
    "min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "b = np.concatenate((replay_buffer.memory.states, replay_buffer.memory.actions), axis=1)\n",
    "a = np.concatenate((replay_buffer.memory[0][0], replay_buffer.memory[1][0])).reshape(1,5)\n",
    "\n",
    "c = dist.cdist(a,b,'euclidean')\n",
    "np.min(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "low >= high",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c481018d60cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model1 = DecisionTreeRegressor()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbatch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbatch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_vfa/function_approximators/replay.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size, device)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         batch = Transition(\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "# model1 = DecisionTreeRegressor()\n",
    "\n",
    "batch1 = replay_buffer.sample(32)\n",
    "batch1.rewards[3] += 1\n",
    "\n",
    "# inputs1 = np.concatenate([batch1.states, [actions[int(i.item())] for i in batch1.actions]], -1)\n",
    "# outputs1 = batch1.rewards\n",
    "\n",
    "inputs1 = np.concatenate([batch1.states, [actions[int(i.item())] for i in batch1.actions]], -1)\n",
    "preds1 =[]\n",
    "for i in range(env.action_space.n):\n",
    "    next_inputs1 = np.concatenate([batch1.next_states, np.zeros((batch1.actions.size()[0], 1))+actions[i]], -1)\n",
    "    preds1.append(model1.predict(next_inputs1))\n",
    "preds1 = np.array(preds1).T\n",
    "outputs1 = batch1.rewards + gamma * (1-batch1.done) * np.max(preds1, 1).reshape(-1,1)\n",
    "print(outputs1)\n",
    "tree.plot_tree(model1)\n",
    "\n",
    "model1.fit(inputs1, outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = replay_buffer.sample(32)\n",
    "np.concatenate([batch.next_states, np.zeros((batch.actions.size()[0], 1)) + actions[0]], -1).shape\n",
    "\n",
    "preds = []\n",
    "for i in range(env.action_space.n):\n",
    "    next_inputs = np.concatenate([batch.next_states, np.zeros((batch.actions.size()[0], 1)) + actions[i]], -1)\n",
    "    preds.append(model.predict(next_inputs))\n",
    "preds = np.array(preds).T\n",
    "outputs = np.array(batch.rewards + gamma * (1-batch.done) * np.max(preds, 1).reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "np.array(batch.rewards).reshape(-1).shape"
   ]
  }
 ]
}