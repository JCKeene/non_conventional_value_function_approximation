{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('rl_vfa_venv': venv)"
  },
  "interpreter": {
   "hash": "ca6e9933f728d920a33c4385152fc811e414d8d97bad348677111d3aff399912"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import gym \n",
    "import numpy as np\n",
    "from custom_envs.gridworlds import WindyGridworldEnv, SimpleGridworldEnv\n",
    "from custom_envs.mountain_car import MountainCarEnv\n",
    "\n",
    "from function_approximators.function_approximators import NeuralNetwork, LinearModel, DecisionTree, RandomForest, SupportVectorRegressor, KNeighboursRegressor, GaussianProcess, OnlineGaussianProcess\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, RationalQuadratic, Matern\n",
    "from sklearn.metrics.pairwise import rbf_kernel, chi2_kernel, laplacian_kernel \n",
    "\n",
    "from utils.train_utils import train, solve, train_time\n",
    "from utils.plot_utils import plot_returns\n",
    "\n",
    "from agents.ad_agents import DQNAgent, LinearAgent, FQIAgent, OnlineGaussianProccessAgent\n",
    "\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Environment\n",
    "\n",
    "function_approximators = [NeuralNetwork, LinearModel, DecisionTree, RandomForest, SupportVectorRegressor, KNeighboursRegressor, GaussianProcess, OnlineGaussianProcess]\n",
    "\n",
    "agents = [DQNAgent, LinearAgent, *[FQIAgent]*5, OnlineGaussianProccessAgent]\n",
    "\n",
    "RENDER = True\n",
    "env = MountainCarEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Config\n",
    "CONFIG_DQN = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 50000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 2500, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"learning_rate\": 0.003,\n",
    "    \"hidden_size\": (32,32),\n",
    "    \"target_update_freq\": 100,\n",
    "    \"batch_size\": 128,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"plot_loss\": False,\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.5,\n",
    "    \"lr_step_size\": 1000,\n",
    "    \"lr_gamma\": 0.95,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": False,\n",
    "}\n",
    "\n",
    "# Linear Config\n",
    "CONFIG_LINEAR = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 50000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 2500, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"target_update_freq\": 200,\n",
    "    \"batch_size\": 64,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e7),\n",
    "    \"plot_loss\": False,\n",
    "    \"epsilon\": 1,\n",
    "    \"max_steps\": 200,\n",
    "    \"poly_degree\": 2,\n",
    "    \"max_deduct\": 0.97,\n",
    "    \"decay\": 0.5,\n",
    "    \"lr_step_size\": 1000,\n",
    "    \"lr_gamma\": 0.99,\n",
    "    \"non_param\": False,\n",
    "}\n",
    "\n",
    "# Decision Tree Config\n",
    "CONFIG_DT = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 50000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 2500, \n",
    "    \"eval_episodes\": 1,\n",
    "    \"model_save_freq\": 100000,\n",
    "    \"model_save_capacity\": 1,\n",
    "    \"update_freq\": 1,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(5e4),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.5,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"criterion\":\"mse\",\"max_depth\": 7, \"min_samples_split\": 2, \"min_samples_leaf\": 1},\n",
    "    \"feature_names\": [\"Cart Position\", \"Cart Velocity\", \"Pole Angle\", \"Pole Angular Velocity\", \"Action: Push Left\", \"Action: Push Right\"],\n",
    "    \"plot_name\": \"dt_depth=8\",\n",
    "}\n",
    "\n",
    "# Random Forest Config\n",
    "CONFIG_RF = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 50000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 2500, \n",
    "    \"eval_episodes\": 1,\n",
    "    \"model_save_freq\": 2500,\n",
    "    \"model_save_capacity\": 20,\n",
    "    \"update_freq\": 5,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.5,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"n_estimators\": 5,\"max_depth\": 5, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "}\n",
    "\n",
    "# Support Vector Regressor Config\n",
    "CONFIG_SVR = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 50000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 2500, \n",
    "    \"eval_episodes\": 1,\n",
    "    \"model_save_freq\": 100000,\n",
    "    \"model_save_capacity\": 1,\n",
    "    \"update_freq\": 1,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e4),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.4,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"kernel\":\"rbf\", \"degree\": 2, \"C\": 1},\n",
    "}\n",
    "\n",
    "\n",
    "# K-Neighbors Regressor Config\n",
    "CONFIG_KNR = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 50000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 2500, \n",
    "    \"eval_episodes\": 1,\n",
    "    \"model_save_freq\": 2500,\n",
    "    \"model_save_capacity\": 20,\n",
    "    \"update_freq\": 1,\n",
    "    \"batch_size\": 256,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.4,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"n_neighbors\":7, \"weights\": \"distance\", \"algorithm\": \"auto\", \"leaf_size\": 30},\n",
    "}\n",
    "\n",
    "# Gaussian Process Config\n",
    "CONFIG_GP = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 5,\n",
    "    \"model_save_freq\": 1000,\n",
    "    \"model_save_capacity\": 20,\n",
    "    \"update_freq\": 10,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.3,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"alpha\": 1e-10, \"normalize_y\": False, \"kernel\":  RBF(length_scale=0.08, length_scale_bounds=\"fixed\")},\n",
    "}\n",
    "\n",
    "# Online Gaussian Process Config\n",
    "CONFIG_GP_Online = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 50000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 2500, \n",
    "    \"eval_episodes\": 1,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"batch_size\": 32,\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.3,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"sigma_0\": 0.5, \"init\": -100, \"kernel\":  rbf_kernel, \"epsilon_tol\": 0.05, \"basis_limit\": 1000},\n",
    "}\n",
    "\n",
    "CONFIGS = [CONFIG_DQN, CONFIG_LINEAR, CONFIG_DT, CONFIG_RF, CONFIG_SVR, CONFIG_KNR, CONFIG_GP, CONFIG_GP_Online]\n",
    "onlines = [False, False, False, False, False, False, False, True]\n",
    "models = [\"Neural Network\", \"Linear Model\", \"Decision Tree\", \"Random Forest\", \"Support Vectors\", \"K-Neighbours\", \"Gaussian Process\", \"Gaussian Process Online\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 800/50000 [00:00<00:07, 6295.40it/s]\n",
      " Run: 1 \n",
      "\n",
      "  5%|▌         | 2600/50000 [00:10<02:37, 300.72it/s]Evaluation at timestep 2600 returned a mean returns of -200.0\n",
      "Epsilon = 0.9088\n",
      "Replay Buffer count: 1201\n",
      " 10%|█         | 5000/50000 [00:26<04:27, 168.11it/s]Evaluation at timestep 5000 returned a mean returns of -200.0\n",
      "Epsilon = 0.8176\n",
      "Replay Buffer count: 1934\n",
      " 15%|█▌        | 7600/50000 [00:48<05:10, 136.42it/s]Evaluation at timestep 7600 returned a mean returns of -200.0\n",
      "Epsilon = 0.7188000000000001\n",
      "Replay Buffer count: 2317\n",
      " 20%|██        | 10000/50000 [01:10<05:30, 121.01it/s]Evaluation at timestep 10000 returned a mean returns of -200.0\n",
      "Epsilon = 0.6275999999999999\n",
      "Replay Buffer count: 2615\n",
      " 25%|██▌       | 12600/50000 [01:36<05:35, 111.40it/s]Evaluation at timestep 12600 returned a mean returns of -200.0\n",
      "Epsilon = 0.5288\n",
      "Replay Buffer count: 2879\n",
      " 30%|███       | 15000/50000 [02:02<05:45, 101.39it/s]Evaluation at timestep 15000 returned a mean returns of -200.0\n",
      "Epsilon = 0.4376000000000001\n",
      "Replay Buffer count: 3076\n",
      " 35%|███▌      | 17600/50000 [02:32<05:41, 94.80it/s]Evaluation at timestep 17600 returned a mean returns of -200.0\n",
      "Epsilon = 0.3388000000000001\n",
      "Replay Buffer count: 3396\n",
      " 40%|████      | 20000/50000 [03:02<05:43, 87.26it/s]Evaluation at timestep 20000 returned a mean returns of -200.0\n",
      "Epsilon = 0.24760000000000004\n",
      "Replay Buffer count: 3610\n",
      " 45%|████▌     | 22600/50000 [03:36<05:21, 85.16it/s]Evaluation at timestep 22600 returned a mean returns of -200.0\n",
      "Epsilon = 0.14880000000000004\n",
      "Replay Buffer count: 3711\n",
      " 50%|█████     | 25000/50000 [04:08<05:01, 82.96it/s]Evaluation at timestep 25000 returned a mean returns of -200.0\n",
      "Epsilon = 0.057600000000000096\n",
      "Replay Buffer count: 3816\n",
      " 55%|█████▌    | 27600/50000 [04:42<04:33, 81.91it/s]Evaluation at timestep 27600 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 3859\n",
      " 60%|██████    | 30000/50000 [05:15<04:08, 80.39it/s]Evaluation at timestep 30000 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 3886\n",
      " 65%|██████▌   | 32600/50000 [05:51<03:38, 79.60it/s]Evaluation at timestep 32600 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 3912\n",
      " 70%|███████   | 35000/50000 [06:24<03:11, 78.44it/s]Evaluation at timestep 35000 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 4004\n",
      " 75%|███████▌  | 37600/50000 [07:01<02:37, 78.76it/s]Evaluation at timestep 37600 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 4031\n",
      " 80%|████████  | 40000/50000 [07:34<02:07, 78.30it/s]Evaluation at timestep 40000 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 4058\n",
      " 85%|████████▌ | 42600/50000 [08:11<01:34, 77.91it/s]Evaluation at timestep 42600 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 4088\n",
      " 90%|█████████ | 45000/50000 [08:45<01:04, 76.99it/s]Evaluation at timestep 45000 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 4096\n",
      " 95%|█████████▌| 47600/50000 [09:22<00:31, 76.93it/s]Evaluation at timestep 47600 returned a mean returns of -200.0\n",
      "Epsilon = 0.050000000000000044\n",
      "Replay Buffer count: 4114\n",
      " 98%|█████████▊| 48800/50000 [09:39<00:14, 84.28it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4285e5dac6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Run: {i+1} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     r, _, t, times = train(env, \n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mCONFIGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mfa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_approximators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_vfa/utils/train_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(env, config, fa, agent, output, render, online, threshold)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps_elapsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_timesteps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             episode_timesteps, train_return, losses = play_episode(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_vfa/utils/train_utils.py\u001b[0m in \u001b[0;36mplay_episode\u001b[0;34m(env, agent, replay_buffer, non_param, max_steps, online, batch_size, train, explore, render)\u001b[0m\n\u001b[1;32m     87\u001b[0m                         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"q_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_vfa/agents/ad_agents.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoded_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl_vfa/agents/ad_agents.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoded_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Performance Evaluation\n",
    "\n",
    "returns = []\n",
    "train_returns = []\n",
    "train_times = []\n",
    "n_seeds=1\n",
    "\n",
    "j=2\n",
    "for i in range(n_seeds):\n",
    "    print(f\"\\n Run: {i+1} \\n\")\n",
    "    r, _, t, times = train(env, \n",
    "            CONFIGS[j], \n",
    "            fa=function_approximators[j], \n",
    "            agent = agents[j], \n",
    "            render=RENDER,\n",
    "            online=onlines[j],\n",
    "            threshold=0.003)\n",
    "    env.close()\n",
    "    returns.append(r)\n",
    "    train_returns.append(t)\n",
    "    train_times.append(times)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'simplegrid_eval_{models[j]}.csv', 'ab') as eval:\n",
    "    for i in range(n_seeds):\n",
    "        np.savetxt(eval, [returns[i]], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'simplegrid_train_{models[j]}.csv', 'ab') as train:\n",
    "    for i in range(n_seeds):\n",
    "        np.savetxt(train, [train_returns[i]], delimiter=',')\n",
    "        np.savetxt(train, [train_times[i]], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " Run: 1 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 762\n",
      "Total episodes: 22\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 2 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 728\n",
      "Total episodes: 19\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 3 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 282\n",
      "Total episodes: 7\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 4 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 425\n",
      "Total episodes: 10\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 5 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 282\n",
      "Total episodes: 10\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 6 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 710\n",
      "Total episodes: 18\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 7 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 1075\n",
      "Total episodes: 25\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 8 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 521\n",
      "Total episodes: 19\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 9 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 412\n",
      "Total episodes: 12\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 10 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 400\n",
      "Total episodes: 12\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 11 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 651\n",
      "Total episodes: 18\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 12 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 482\n",
      "Total episodes: 15\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 13 \n",
      "\n",
      "\n",
      " Run: 14 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 356\n",
      "Total episodes: 11\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 15 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 200\n",
      "Total episodes: 4\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 16 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 211\n",
      "Total episodes: 6\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 17 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 228\n",
      "Total episodes: 5\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 18 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 267\n",
      "Total episodes: 9\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 19 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 453\n",
      "Total episodes: 14\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 20 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 484\n",
      "Total episodes: 12\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 21 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 277\n",
      "Total episodes: 8\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 22 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 482\n",
      "Total episodes: 12\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 23 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 348\n",
      "Total episodes: 13\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 24 \n",
      "\n",
      "\n",
      " Run: 25 \n",
      "\n",
      "\n",
      " Run: 26 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 264\n",
      "Total episodes: 7\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 27 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 298\n",
      "Total episodes: 11\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 28 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 526\n",
      "Total episodes: 18\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 29 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 448\n",
      "Total episodes: 14\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 30 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 404\n",
      "Total episodes: 10\n",
      "Evaluation mean return: -5.999999999999999\n"
     ]
    }
   ],
   "source": [
    "## Sample Efficiency Evaluation\n",
    "\n",
    "n_eps = []\n",
    "n_steps = []\n",
    "not_solved = []\n",
    "n_seeds=30\n",
    "\n",
    "j=7\n",
    "for i in range(n_seeds):\n",
    "    print(f\"\\n Run: {i+1} \\n\")\n",
    "    s, e, n = solve(env, \n",
    "            CONFIGS[j], \n",
    "            fa=function_approximators[j], \n",
    "            agent = agents[j],\n",
    "            target_return=-6,\n",
    "            op=operator.ge, \n",
    "            render=RENDER,\n",
    "            online=onlines[j])\n",
    "    env.close()\n",
    "    n_eps.append(e)\n",
    "    n_steps.append(s)\n",
    "    not_solved.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'simplegrid_se-6_{models[j]}.csv', 'ab') as se:\n",
    "    np.savetxt(se, [n_eps], delimiter=',')\n",
    "    np.savetxt(se, [n_steps], delimiter=',')\n",
    "    np.savetxt(se, [not_solved], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average n_eps: 21.633333333333333\nStd n_eps: 27.45721924902245\nSt.error n_eps: 5.0129794496848845\nAverage n_steps: 900.60\nStd n_steps: 1383.9435826651315\nSt.error n_steps: 252.67237284673604\nNot solved: 3 runs\n"
     ]
    }
   ],
   "source": [
    "mean_eps = np.mean(n_eps)\n",
    "std_eps = np.std(n_eps)\n",
    "print(f\"Average n_eps: {mean_eps}\")\n",
    "print(f\"Std n_eps: {std_eps}\")\n",
    "print(f\"St.error n_eps: {std_eps/np.sqrt(n_seeds)}\")\n",
    "\n",
    "mean_steps = np.mean(n_steps)\n",
    "std_steps = np.std(n_steps)\n",
    "print(f\"Average n_steps: {mean_steps}0\")\n",
    "print(f\"Std n_steps: {std_steps}\")\n",
    "print(f\"St.error n_steps: {std_steps/np.sqrt(n_seeds)}\")\n",
    "\n",
    "print(f\"Not solved: {np.sum(not_solved)} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "5005it [00:06, 732.22it/s]                          \n",
      "  3%|▎         | 173/5000 [00:00<00:02, 1637.78it/s]-6\n",
      "5006it [00:03, 1297.35it/s]                          \n",
      " 11%|█▏        | 566/5000 [00:00<00:01, 3382.90it/s]-8\n",
      "100%|██████████| 5000/5000 [00:37<00:00, 134.49it/s]\n",
      " 11%|█         | 549/5000 [00:00<00:01, 3684.31it/s]-6\n",
      "5007it [02:02, 40.97it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]-8\n",
      "5001it [03:33, 23.42it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]-6\n",
      "5003it [09:31,  8.75it/s]\n",
      " 11%|█         | 531/5000 [00:00<00:01, 2983.59it/s]-6\n",
      "100%|██████████| 5000/5000 [04:40<00:00, 17.83it/s]\n",
      "  1%|          | 28/5000 [00:00<00:20, 246.46it/s]-6\n",
      "5004it [00:56, 89.35it/s]                          -6\n",
      "56.0056312084198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training time\n",
    "\n",
    "times = []\n",
    "for j in range(8):\n",
    "        time = train_time(env, \n",
    "                CONFIGS[j], \n",
    "                fa=function_approximators[j], \n",
    "                agent = agents[j],\n",
    "                online=onlines[j])\n",
    "        env.close()\n",
    "        times.append(time)\n",
    "\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'simplegrid_times.csv', 'ab') as t:\n",
    "    np.savetxt(t, [times], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}