{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import gym \n",
    "import numpy as np\n",
    "\n",
    "from function_approximators.function_approximators import NeuralNetwork, LinearModel, DecisionTree, RandomForest, SupportVectorRegressor, KNeighboursRegressor, GaussianProcess, OnlineGaussianProcess\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "from utils.train_utils import train, solve, train_time\n",
    "from agents.agents import DQNAgent, LinearAgent, FQIAgent, OnlineGaussianProccessAgent\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Environment\n",
    "\n",
    "function_approximators = [NeuralNetwork, LinearModel, DecisionTree, RandomForest, SupportVectorRegressor, KNeighboursRegressor, GaussianProcess, OnlineGaussianProcess]\n",
    "\n",
    "agents = [DQNAgent, LinearAgent, *[FQIAgent]*5, OnlineGaussianProccessAgent]\n",
    "\n",
    "RENDER = False\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Config\n",
    "CONFIG_DQN = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"learning_rate\": 0.00075,\n",
    "    \"hidden_size\": (32,32),\n",
    "    \"target_update_freq\": 200,\n",
    "    \"batch_size\": 32,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"plot_loss\": False,\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.97,\n",
    "    \"decay\": 0.25,\n",
    "    \"lr_step_size\": 1000,\n",
    "    \"lr_gamma\": 0.95,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": False,\n",
    "}\n",
    "\n",
    "# Linear Config\n",
    "CONFIG_LINEAR = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"target_update_freq\": 50,\n",
    "    \"batch_size\": 32,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e7),\n",
    "    \"plot_loss\": False,\n",
    "    \"epsilon\": 1,\n",
    "    \"max_steps\": 200,\n",
    "    \"poly_degree\": 2,\n",
    "    \"max_deduct\": 0.97,\n",
    "    \"decay\": 0.5,\n",
    "    \"lr_step_size\": 1000,\n",
    "    \"lr_gamma\": 0.99,\n",
    "    \"non_param\": False,\n",
    "}\n",
    "\n",
    "# Decision Tree Config\n",
    "CONFIG_DT = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"model_save_freq\": 1000,\n",
    "    \"model_save_capacity\": 20,\n",
    "    \"update_freq\": 1,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.4,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"criterion\":\"mse\",\"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    \"feature_names\": [\"Cart Position\", \"Cart Velocity\", \"Pole Angle\", \"Pole Angular Velocity\", \"Action: Push Left\", \"Action: Push Right\"],\n",
    "    \"plot_name\": \"dt_depth=8\",\n",
    "}\n",
    "\n",
    "# Random Forest Config\n",
    "CONFIG_RF = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"model_save_freq\": 1000,\n",
    "    \"model_save_capacity\": 20,\n",
    "    \"update_freq\": 5,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.4,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"n_estimators\": 10,\"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "}\n",
    "\n",
    "# Support Vector Regressor Config\n",
    "CONFIG_SVR = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"model_save_freq\": 1000,\n",
    "    \"model_save_capacity\": 20,\n",
    "    \"update_freq\": 1,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.3,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"kernel\":\"rbf\", \"degree\": 2, \"C\": 2},\n",
    "}\n",
    "\n",
    "\n",
    "# K-Neighbors Regressor Config\n",
    "CONFIG_KNR = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"model_save_freq\": 1000,\n",
    "    \"model_save_capacity\": 20,\n",
    "    \"update_freq\": 1,\n",
    "    \"batch_size\": 256,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.3,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"n_neighbors\":7, \"weights\": \"distance\", \"algorithm\": \"auto\", \"leaf_size\": 30},\n",
    "}\n",
    "\n",
    "# Gaussian Process Config\n",
    "CONFIG_GP = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"model_save_freq\": 1000,\n",
    "    \"model_save_capacity\": 20,\n",
    "    \"update_freq\": 10,\n",
    "    \"batch_size\": 512,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.3,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"alpha\": 1e-10, \"normalize_y\": False, \"kernel\":  RBF(length_scale=0.08, length_scale_bounds=\"fixed\")},\n",
    "}\n",
    "\n",
    "# Online Gaussian Process Config\n",
    "CONFIG_GP_Online = {\n",
    "    \"episode_length\": 200,\n",
    "    \"max_timesteps\": 20000,\n",
    "    \"max_time\": 30 * 60,\n",
    "    \"eval_freq\": 1000, \n",
    "    \"eval_episodes\": 10,\n",
    "    \"gamma\": 0.99,\n",
    "    \"buffer_capacity\": int(1e6),\n",
    "    \"batch_size\": 32,\n",
    "    \"epsilon\": 1,\n",
    "    \"max_deduct\": 0.95,\n",
    "    \"decay\": 0.3,\n",
    "    \"max_steps\": 200,\n",
    "    \"non_param\": True,\n",
    "    \"model_params\": {\"sigma_0\": 0.5, \"kernel\":  rbf_kernel, \"epsilon_tol\": 0.05, \"basis_limit\": 1000},\n",
    "}\n",
    "\n",
    "CONFIGS = [CONFIG_DQN, CONFIG_LINEAR, CONFIG_DT, CONFIG_RF, CONFIG_SVR, CONFIG_KNR, CONFIG_GP, CONFIG_GP_Online]\n",
    "onlines = [False, False, False, False, False, False, False, True]\n",
    "models = [\"Neural Network\", \"Linear Model\", \"Decision Tree\", \"Random Forest\", \"Support Vectors\", \"K-Neighbours\", \"Gaussian Process\", \"Gaussian Process Online\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Performance Evaluation\n",
    "\n",
    "RENDER = False\n",
    "\n",
    "returns = []\n",
    "train_returns = []\n",
    "train_times = []\n",
    "n_seeds=30\n",
    "\n",
    "j=2\n",
    "for i in range(n_seeds):\n",
    "    print(f\"\\n Run: {i+1} \\n\")\n",
    "    r, _, t, times = train(env, \n",
    "            CONFIGS[j], \n",
    "            fa=function_approximators[j], \n",
    "            agent = agents[j], \n",
    "            render=RENDER,\n",
    "            online=onlines[j],\n",
    "            threshold = 0)\n",
    "    env.close()\n",
    "    returns.append(r)\n",
    "    train_returns.append(t)\n",
    "    train_times.append(times)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Run: 1 \n",
      "\n",
      "HERE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9073b73b49480584c0d2d1af253f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation at timestep 1015 returned a mean returns of 63.8\n",
      "Epsilon = 0.812984\n",
      "Learning rate = 0.00075\n",
      "Replay Buffer count: 1015\n",
      "Evaluation at timestep 2044 returned a mean returns of 186.60000000000002\n",
      "Epsilon = 0.617432\n",
      "Learning rate = 0.000676875\n",
      "Replay Buffer count: 2044\n",
      "Evaluation at timestep 3090 returned a mean returns of 193.7\n",
      "Epsilon = 0.436624\n",
      "Learning rate = 0.0006430312499999999\n",
      "Replay Buffer count: 3090\n",
      "Evaluation at timestep 4103 returned a mean returns of 186.29999999999998\n",
      "Epsilon = 0.24029600000000007\n",
      "Learning rate = 0.0006108796874999999\n",
      "Replay Buffer count: 4103\n",
      "Evaluation at timestep 5015 returned a mean returns of 177.89999999999998\n",
      "Epsilon = 0.05910000000000004\n",
      "Learning rate = 0.0006108796874999999\n",
      "Replay Buffer count: 5015\n",
      "Evaluation at timestep 6043 returned a mean returns of 141.70000000000002\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.0005513189179687499\n",
      "Replay Buffer count: 6043\n",
      "Evaluation at timestep 7062 returned a mean returns of 143.5\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.0005237529720703124\n",
      "Replay Buffer count: 7062\n",
      "Evaluation at timestep 8012 returned a mean returns of 149.29999999999998\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.0005237529720703124\n",
      "Replay Buffer count: 8012\n",
      "Evaluation at timestep 9063 returned a mean returns of 140.8\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.00047268705729345693\n",
      "Replay Buffer count: 9063\n",
      "Evaluation at timestep 10011 returned a mean returns of 188.29999999999998\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.00047268705729345693\n",
      "Replay Buffer count: 10011\n",
      "Evaluation at timestep 11068 returned a mean returns of 105.10000000000001\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.00042660006920734484\n",
      "Replay Buffer count: 11068\n",
      "Evaluation at timestep 12023 returned a mean returns of 106.8\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.00042660006920734484\n",
      "Replay Buffer count: 12023\n",
      "Evaluation at timestep 13072 returned a mean returns of 109.60000000000001\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.0003850065624596287\n",
      "Replay Buffer count: 13072\n",
      "Evaluation at timestep 14046 returned a mean returns of 111.2\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.00036575623433664727\n",
      "Replay Buffer count: 14046\n",
      "Evaluation at timestep 15027 returned a mean returns of 118.19999999999999\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.00036575623433664727\n",
      "Replay Buffer count: 15027\n",
      "Evaluation at timestep 16056 returned a mean returns of 163.8\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.0003300950014888241\n",
      "Replay Buffer count: 16056\n",
      "Evaluation at timestep 17077 returned a mean returns of 181.9\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.0003135902514143829\n",
      "Replay Buffer count: 17077\n",
      "Evaluation at timestep 18009 returned a mean returns of 199.2\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.0003135902514143829\n",
      "Replay Buffer count: 18009\n",
      "Evaluation at timestep 19089 returned a mean returns of 190.4\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.0002830152019014805\n",
      "Replay Buffer count: 19089\n",
      "Evaluation at timestep 20144 returned a mean returns of 191.40000000000003\n",
      "Epsilon = 0.030000000000000027\n",
      "Learning rate = 0.00026886444180640646\n",
      "Replay Buffer count: 20144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(166, 166.0, [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train agent using NN:\n",
    "from utils.train_utils import trainAgent, play_episode\n",
    "from function_approximators.replay import ReplayBuffer\n",
    "\n",
    "env = gym()\n",
    "\n",
    "# Train NN agent\n",
    "j=0\n",
    "config = CONFIGS[j]\n",
    "print(f\"\\n Run: {1} \\n\")\n",
    "trainedAgent = trainAgent(env, \n",
    "        CONFIGS[j], \n",
    "        fa=function_approximators[j], \n",
    "        agent = agents[j], \n",
    "        render=RENDER,\n",
    "        online=onlines[j],\n",
    "        threshold = 0)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = ReplayBuffer(config[\"buffer_capacity\"], 0)\n",
    "\n",
    "play_episode(env, trainedAgent,\n",
    "                        rb,\n",
    "                        train=False,\n",
    "                        explore=False,\n",
    "                        render=True,\n",
    "                        online=onlines[j],\n",
    "                        threshold=0,\n",
    "                        non_param = config[\"non_param\"],\n",
    "                        max_steps = config[\"max_steps\"],\n",
    "                        batch_size=config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output trained agent attempt\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'cartpole_eval_{models[j]}.csv', 'ab') as eval:\n",
    "    for i in range(n_seeds):\n",
    "        np.savetxt(eval, [returns[i]], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'cartpole_train_{models[j]}.csv', 'ab') as train:\n",
    "    for i in range(n_seeds):\n",
    "        np.savetxt(train, [train_returns[i]], delimiter=',')\n",
    "        np.savetxt(train, [train_times[i]], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Run: 1 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 762\n",
      "Total episodes: 22\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 2 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 728\n",
      "Total episodes: 19\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 3 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 282\n",
      "Total episodes: 7\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 4 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 425\n",
      "Total episodes: 10\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 5 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 282\n",
      "Total episodes: 10\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 6 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 710\n",
      "Total episodes: 18\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 7 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 1075\n",
      "Total episodes: 25\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 8 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 521\n",
      "Total episodes: 19\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 9 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 412\n",
      "Total episodes: 12\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 10 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 400\n",
      "Total episodes: 12\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 11 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 651\n",
      "Total episodes: 18\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 12 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 482\n",
      "Total episodes: 15\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 13 \n",
      "\n",
      "\n",
      " Run: 14 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 356\n",
      "Total episodes: 11\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 15 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 200\n",
      "Total episodes: 4\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 16 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 211\n",
      "Total episodes: 6\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 17 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 228\n",
      "Total episodes: 5\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 18 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 267\n",
      "Total episodes: 9\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 19 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 453\n",
      "Total episodes: 14\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 20 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 484\n",
      "Total episodes: 12\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 21 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 277\n",
      "Total episodes: 8\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 22 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 482\n",
      "Total episodes: 12\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 23 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 348\n",
      "Total episodes: 13\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 24 \n",
      "\n",
      "\n",
      " Run: 25 \n",
      "\n",
      "\n",
      " Run: 26 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 264\n",
      "Total episodes: 7\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 27 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 298\n",
      "Total episodes: 11\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 28 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 526\n",
      "Total episodes: 18\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 29 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 448\n",
      "Total episodes: 14\n",
      "Evaluation mean return: -5.999999999999999\n",
      "\n",
      " Run: 30 \n",
      "\n",
      "Ep. timesteps: 6\n",
      "Total timesteps: 404\n",
      "Total episodes: 10\n",
      "Evaluation mean return: -5.999999999999999\n"
     ]
    }
   ],
   "source": [
    "## Sample Efficiency Evaluation\n",
    "\n",
    "n_eps = []\n",
    "n_steps = []\n",
    "not_solved = []\n",
    "n_seeds=30\n",
    "\n",
    "j=7\n",
    "for i in range(n_seeds):\n",
    "    print(f\"\\n Run: {i+1} \\n\")\n",
    "    s, e, n = solve(env, \n",
    "            CONFIGS[j], \n",
    "            fa=function_approximators[j], \n",
    "            agent = agents[j],\n",
    "            target_return=-6,\n",
    "            op=operator.ge, \n",
    "            render=RENDER,\n",
    "            online=onlines[j])\n",
    "    env.close()\n",
    "    n_eps.append(e)\n",
    "    n_steps.append(s)\n",
    "    not_solved.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'cartpole_{models[j]}.csv', 'ab') as se:\n",
    "    np.savetxt(se, [n_eps], delimiter=',')\n",
    "    np.savetxt(se, [n_steps], delimiter=',')\n",
    "    np.savetxt(se, [not_solved], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average n_eps: 21.633333333333333\n",
      "Std n_eps: 27.45721924902245\n",
      "St.error n_eps: 5.0129794496848845\n",
      "Average n_steps: 900.60\n",
      "Std n_steps: 1383.9435826651315\n",
      "St.error n_steps: 252.67237284673604\n",
      "Not solved: 3 runs\n"
     ]
    }
   ],
   "source": [
    "mean_eps = np.mean(n_eps)\n",
    "std_eps = np.std(n_eps)\n",
    "print(f\"Average n_eps: {mean_eps}\")\n",
    "print(f\"Std n_eps: {std_eps}\")\n",
    "print(f\"St.error n_eps: {std_eps/np.sqrt(n_seeds)}\")\n",
    "\n",
    "mean_steps = np.mean(n_steps)\n",
    "std_steps = np.std(n_steps)\n",
    "print(f\"Average n_steps: {mean_steps}0\")\n",
    "print(f\"Std n_steps: {std_steps}\")\n",
    "print(f\"St.error n_steps: {std_steps/np.sqrt(n_seeds)}\")\n",
    "\n",
    "print(f\"Not solved: {np.sum(not_solved)} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5005it [00:06, 732.22it/s]                          \n",
      "  3%|▎         | 173/5000 [00:00<00:02, 1637.78it/s]-6\n",
      "5006it [00:03, 1297.35it/s]                          \n",
      " 11%|█▏        | 566/5000 [00:00<00:01, 3382.90it/s]-8\n",
      "100%|██████████| 5000/5000 [00:37<00:00, 134.49it/s]\n",
      " 11%|█         | 549/5000 [00:00<00:01, 3684.31it/s]-6\n",
      "5007it [02:02, 40.97it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]-8\n",
      "5001it [03:33, 23.42it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]-6\n",
      "5003it [09:31,  8.75it/s]\n",
      " 11%|█         | 531/5000 [00:00<00:01, 2983.59it/s]-6\n",
      "100%|██████████| 5000/5000 [04:40<00:00, 17.83it/s]\n",
      "  1%|          | 28/5000 [00:00<00:20, 246.46it/s]-6\n",
      "5004it [00:56, 89.35it/s]                          -6\n",
      "56.0056312084198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training time\n",
    "\n",
    "times = []\n",
    "for j in range(8):\n",
    "        time = train_time(env, \n",
    "                CONFIGS[j], \n",
    "                fa=function_approximators[j], \n",
    "                agent = agents[j],\n",
    "                online=onlines[j])\n",
    "        env.close()\n",
    "        times.append(time)\n",
    "\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'cartpole_times.csv', 'ab') as t:\n",
    "    np.savetxt(t, [times], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca6e9933f728d920a33c4385152fc811e414d8d97bad348677111d3aff399912"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('rl_vfa_venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
